{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Custom Pipeline\n",
    "\n",
    "by Simon BÃ¶ck\n",
    "\n",
    "The structure in general is kept very simple:\n",
    "- Feed the Speech-to-text API by Google Cloud with the corresponding audio file\n",
    "- Feed the DeepL API with the correspoinding output of the Speech-to-text API of Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-speech google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import ffmpeg\n",
    "import requests\n",
    "from google.cloud import speech, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'your_key.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding audio file is uploaded to the Google Cloud Storage, due to its size. Otherwise it would not be able to run that smoothly. The upload and creation of such bucket, in which you can store the files needed is very simple and can looked up here https://cloud.google.com/storage?hl=en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the large audio file to Google Cloud Storage\n",
    "storage_client = storage.Client()\n",
    "\n",
    "bucket = storage_client.get_bucket('bucket-name')  # Replace with your bucket name\n",
    "\n",
    "#Prepare the URI for the audio file in Google Cloud Storage\n",
    "gcs_uri = 'gs://bucket-name/file.wav'\n",
    "\n",
    "# Configure the audio file's settings for the recognition request\n",
    "long_running_recognize_config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=44100,\n",
    "    language_code=\"de-DE\",\n",
    "    audio_channel_count=2\n",
    ")\n",
    "\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "# Asynchronously transcribe the audio\n",
    "operation = client.long_running_recognize(config=long_running_recognize_config, audio=audio)\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "response = operation.result(timeout=600)  # Adjust timeout as needed\n",
    "\n",
    "# Open a file to write the transcriptions\n",
    "with open('transcription_output.txt', 'w') as file:\n",
    "    for result in response.results:\n",
    "        file.write(result.alternatives[0].transcript + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_with_deepl(text_file, api_key):\n",
    "\n",
    "    try:\n",
    "        # Attempt to read the file with UTF-8 encoding\n",
    "        with open(text_file, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # If UTF-8 fails, try reading with ISO-8859-1 encoding\n",
    "        with open(text_file, 'r', encoding='iso-8859-1') as file:\n",
    "            text = file.read()\n",
    "\n",
    "    url = \"https://api-free.deepl.com/v2/translate\"\n",
    "    headers = {\"Authorization\": f\"DeepL-Auth-Key {api_key}\"}\n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        \"target_lang\": \"EN\",\n",
    "        \"source_lang\": \"DE\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        translations = json_response.get('translations', [])\n",
    "        if translations:\n",
    "            translated_text = translations[0].get('text', 'No translation found.')\n",
    "            # Save the translated text to a file\n",
    "            output_file = 'translated_output.txt'\n",
    "            with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "                out_file.write(translated_text)\n",
    "            return f\"Translated text saved to {output_file}.\"\n",
    "        else:\n",
    "            return \"No translation found.\"\n",
    "    else:\n",
    "        return f\"API Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "api_key = \"your_key\"  # Replace this with your actual DeepL API key\n",
    "translated_text = translate_text_with_deepl(\"transcription_output.txt\", api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
