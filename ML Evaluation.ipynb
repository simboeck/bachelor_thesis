{"cells":[{"cell_type":"markdown","metadata":{"id":"WD9YWbV0AaFt"},"source":["# Machine Translation Automatic Metrics\n","\n","- BLEU\n","- chrF\n","- COMET"]},{"cell_type":"markdown","metadata":{},"source":["### Install the packages for the metrics\n","\n","Python version: 3.9.12"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5871,"status":"ok","timestamp":1723802568400,"user":{"displayName":"Fabian","userId":"10617760364168038693"},"user_tz":-120},"id":"ZLn9O7DJAULH","outputId":"5a013090-dcbb-49ce-a153-c0c65a4911a0"},"outputs":[],"source":["## install BLEU and chrF\n","# !pip install sacrebleu"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["## In order to make the COMET installation work we need to install sentencepiece\n","#pip install sentencepiece"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21197,"status":"ok","timestamp":1686413544263,"user":{"displayName":"Fabian","userId":"10617760364168038693"},"user_tz":-120},"id":"M-q3SyRoBHjC","outputId":"1012210f-d93f-4b9a-9d00-8d88ccb7f10e"},"outputs":[],"source":["##install COMET\n","# !pip install unbabel-comet"]},{"cell_type":"markdown","metadata":{},"source":["# Compute the Scores\n","We will now compute the scores for our different files:\n","\n","- US output from HeyGen (online service provider)\n","- Uk output from HeyGen (online service provider)\n","- Custom Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["## Compute the BLEU Scores\n","\n","- sacrebleu reference-file -i MT output -m bleu -l language pair"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619,"status":"ok","timestamp":1686413981097,"user":{"displayName":"Fabian","userId":"10617760364168038693"},"user_tz":-120},"id":"EB2xGXQmCI3k","outputId":"6b6d5735-6cf2-493f-c77e-57059d1e6115"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 29.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"62.9/35.3/22.1/14.4 (BP = 1.000 ratio = 1.086 hyp_len = 1421 ref_len = 1309)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute BLEU for the UK version of HeyGen\n","!sacrebleu human_translation.txt -i heygen_us.txt -m bleu -l en-en"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 28.2,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"62.0/34.1/21.4/14.0 (BP = 1.000 ratio = 1.101 hyp_len = 1441 ref_len = 1309)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute BLEU for the UK version of HeyGen\n","!sacrebleu human_translation.txt -i heygen_uk.txt -m bleu -l en-en"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 23.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"57.4/28.8/16.5/10.3 (BP = 1.000 ratio = 1.086 hyp_len = 1421 ref_len = 1309)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute BLEU for the output of the custom pipeline \n","!sacrebleu human_translation.txt -i custom_pipeline.txt -m bleu -l en-en"]},{"cell_type":"markdown","metadata":{},"source":["## Compute the chrF Scores\n","\n","- sacrebleu reference-file -i MT output -m chrf -l language pair"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"chrF2\",\n"," \"score\": 64.6,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.3\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute chrF for the US version of HeyGen \n","!sacrebleu human_translation.txt -i heygen_us.txt -m chrf -l en-en"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"chrF2\",\n"," \"score\": 63.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.3\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute chrF for the UK version of HeyGen \n","!sacrebleu human_translation.txt -i heygen_uk.txt -m chrf -l en-en"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"chrF2\",\n"," \"score\": 59.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.3\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.3\"\n","}\n"]}],"source":["#compute chrF for the output of the custom pipeline\n","!sacrebleu human_translation.txt -i custom_pipeline.txt -m chrf -l en-en"]},{"cell_type":"markdown","metadata":{"id":"yug2ryzEEnB6"},"source":["## Compute the COMET Scores\n","\n","- comet-score -s source-file  -t MT ouput -r reference-file"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23329,"status":"ok","timestamp":1686414153095,"user":{"displayName":"Fabian","userId":"10617760364168038693"},"user_tz":-120},"id":"mrapRBIJENjG","outputId":"eabe3029-fbf3-4a6a-cd0b-a81a67869077"},"outputs":[{"name":"stdout","output_type":"stream","text":["heygen_us.txt\tSegment 0\tscore: 0.8450\n","heygen_us.txt\tSegment 1\tscore: 0.8225\n","heygen_us.txt\tSegment 2\tscore: 0.8277\n","heygen_us.txt\tSegment 3\tscore: 0.7303\n","heygen_us.txt\tSegment 4\tscore: 0.7622\n","heygen_us.txt\tSegment 5\tscore: 0.7072\n","heygen_us.txt\tSegment 6\tscore: 0.6783\n","heygen_us.txt\tSegment 7\tscore: 0.7636\n","heygen_us.txt\tSegment 8\tscore: 0.8071\n","heygen_us.txt\tscore: 0.7715\n"]},{"name":"stderr","output_type":"stream","text":["Seed set to 1\n","\n","Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]\n","Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n","Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\simon\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\371e9839ca4e213dde891b066cf3080f75ec7e72\\checkpoints\\model.ckpt`\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Encoder model frozen.\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","\n","Predicting: 0it [00:00, ?it/s]\n","Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [02:11<00:00, 131.42s/it]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [02:11<00:00, 131.42s/it]\n"]}],"source":["# compute COMET for the US version of HeyGen\n","!comet-score -s original_transscript.txt -t heygen_us.txt -r human_translation.txt"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["heygen_uk.txt\tSegment 0\tscore: 0.8444\n","heygen_uk.txt\tSegment 1\tscore: 0.8246\n","heygen_uk.txt\tSegment 2\tscore: 0.8191\n","heygen_uk.txt\tSegment 3\tscore: 0.7758\n","heygen_uk.txt\tSegment 4\tscore: 0.7714\n","heygen_uk.txt\tSegment 5\tscore: 0.7179\n","heygen_uk.txt\tSegment 6\tscore: 0.7120\n","heygen_uk.txt\tSegment 7\tscore: 0.7550\n","heygen_uk.txt\tSegment 8\tscore: 0.8036\n","heygen_uk.txt\tscore: 0.7804\n"]},{"name":"stderr","output_type":"stream","text":["Seed set to 1\n","\n","Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]\n","Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 5007.53it/s]\n","Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\simon\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\371e9839ca4e213dde891b066cf3080f75ec7e72\\checkpoints\\model.ckpt`\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Encoder model frozen.\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","\n","Predicting: 0it [00:00, ?it/s]\n","Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [02:44<00:00, 164.68s/it]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [02:44<00:00, 164.69s/it]\n"]}],"source":["# compute COMET for the UK version of HeyGen\n","!comet-score -s original_transscript.txt -t heygen_uk.txt -r human_translation.txt"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["custom_pipeline.txt\tSegment 0\tscore: 0.8150\n","custom_pipeline.txt\tSegment 1\tscore: 0.7566\n","custom_pipeline.txt\tSegment 2\tscore: 0.7661\n","custom_pipeline.txt\tSegment 3\tscore: 0.8030\n","custom_pipeline.txt\tSegment 4\tscore: 0.6234\n","custom_pipeline.txt\tSegment 5\tscore: 0.6060\n","custom_pipeline.txt\tSegment 6\tscore: 0.6150\n","custom_pipeline.txt\tSegment 7\tscore: 0.6446\n","custom_pipeline.txt\tSegment 8\tscore: 0.7378\n","custom_pipeline.txt\tscore: 0.7075\n"]},{"name":"stderr","output_type":"stream","text":["Seed set to 1\n","\n","Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]\n","Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n","Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\simon\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\371e9839ca4e213dde891b066cf3080f75ec7e72\\checkpoints\\model.ckpt`\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Encoder model frozen.\n","C:\\Users\\simon\\anaconda\\envs\\DataProcessing1\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","\n","Predicting: 0it [00:00, ?it/s]\n","Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [06:32<00:00, 392.16s/it]\n","Predicting DataLoader 0: 100%|██████████| 1/1 [06:32<00:00, 392.23s/it]\n"]}],"source":["# compute COMET for the output of the custom pipeline\n","!comet-score -s original_transscript.txt -t custom_pipeline.txt -r human_translation.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"DataProcessing1","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
